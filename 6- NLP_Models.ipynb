{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2EroflcEoLB"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import codecs\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import nltk\n",
    "#import gensim\n",
    "#from gensim import corpora, models, similarities\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EEqmbJ7ePlAR",
    "outputId": "d9aa2e80-1949-4890-aad8-2e8159a55fb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Marwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk. corpus.stopwords.words('arabic')\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKeNRj1gEoLH"
   },
   "outputs": [],
   "source": [
    "\n",
    "Lyrics_df = pd.read_csv('farasa_lyrics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "nT5zK7YuEoLJ",
    "outputId": "f5834719-13cd-4431-add8-6e14d0172100"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>songID</th>\n",
       "      <th>Singer</th>\n",
       "      <th>SongTitle</th>\n",
       "      <th>SongWriter</th>\n",
       "      <th>Composer</th>\n",
       "      <th>LyricsOrder</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>SingerNationality</th>\n",
       "      <th>SongDialect</th>\n",
       "      <th>Clean_Lyrics</th>\n",
       "      <th>Lyrics_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1538</td>\n",
       "      <td>ابتسام</td>\n",
       "      <td>اروح لحبايبى</td>\n",
       "      <td>ملامح</td>\n",
       "      <td>بندر بن فهد</td>\n",
       "      <td>1</td>\n",
       "      <td>اروح لاحبابي والاقي الفرح ساكن عينهم</td>\n",
       "      <td>morocco</td>\n",
       "      <td>meghribi</td>\n",
       "      <td>['اروح', 'لاحبابي', 'والاقي', 'الفرح', 'ساكن',...</td>\n",
       "      <td>['اروح', 'احباب', 'اقي', 'فرح', 'ساكن', 'عين']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1538</td>\n",
       "      <td>ابتسام</td>\n",
       "      <td>اروح لحبايبى</td>\n",
       "      <td>ملامح</td>\n",
       "      <td>بندر بن فهد</td>\n",
       "      <td>2</td>\n",
       "      <td>ابتسم لافراحهم وانا من الهم احترق</td>\n",
       "      <td>morocco</td>\n",
       "      <td>meghribi</td>\n",
       "      <td>['ابتسم', 'لافراحهم', 'وانا', 'الهم', 'احترق']</td>\n",
       "      <td>['ابتسم', 'افراح', 'وان', 'هم', 'احترق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1538</td>\n",
       "      <td>ابتسام</td>\n",
       "      <td>اروح لحبايبى</td>\n",
       "      <td>ملامح</td>\n",
       "      <td>بندر بن فهد</td>\n",
       "      <td>3</td>\n",
       "      <td>واسأل جروحي من ترى حس بعذابي منهم</td>\n",
       "      <td>morocco</td>\n",
       "      <td>meghribi</td>\n",
       "      <td>['واسل', 'جروحي', 'ترى', 'حس', 'بعذابي', 'منهم']</td>\n",
       "      <td>['اسل', 'جرح', 'رأى', 'حس', 'عذاب', 'من']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1538</td>\n",
       "      <td>ابتسام</td>\n",
       "      <td>اروح لحبايبى</td>\n",
       "      <td>ملامح</td>\n",
       "      <td>بندر بن فهد</td>\n",
       "      <td>4</td>\n",
       "      <td>وبالحقيقه انصدم محدن معه همي فرق</td>\n",
       "      <td>morocco</td>\n",
       "      <td>meghribi</td>\n",
       "      <td>['وبالحقيقه', 'انصدم', 'محدن', 'معه', 'همي', '...</td>\n",
       "      <td>['حقيقه', 'انصدم', 'محدن', 'مع', 'هم', 'فرق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1538</td>\n",
       "      <td>ابتسام</td>\n",
       "      <td>اروح لحبايبى</td>\n",
       "      <td>ملامح</td>\n",
       "      <td>بندر بن فهد</td>\n",
       "      <td>5</td>\n",
       "      <td>دورت في كل الوجيه حسيت غربه بينهم</td>\n",
       "      <td>morocco</td>\n",
       "      <td>meghribi</td>\n",
       "      <td>['دورت', 'الوجيه', 'حسيت', 'غربه', 'بينهم']</td>\n",
       "      <td>['دورة', 'وجيه', 'حسي', 'غرب', 'بين']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  songID  Singer     SongTitle SongWriter  \\\n",
       "0          16            16    1538  ابتسام  اروح لحبايبى      ملامح   \n",
       "1          17            17    1538  ابتسام  اروح لحبايبى      ملامح   \n",
       "2          18            18    1538  ابتسام  اروح لحبايبى      ملامح   \n",
       "3          19            19    1538  ابتسام  اروح لحبايبى      ملامح   \n",
       "4          20            20    1538  ابتسام  اروح لحبايبى      ملامح   \n",
       "\n",
       "      Composer  LyricsOrder                                Lyrics  \\\n",
       "0  بندر بن فهد            1  اروح لاحبابي والاقي الفرح ساكن عينهم   \n",
       "1  بندر بن فهد            2     ابتسم لافراحهم وانا من الهم احترق   \n",
       "2  بندر بن فهد            3     واسأل جروحي من ترى حس بعذابي منهم   \n",
       "3  بندر بن فهد            4      وبالحقيقه انصدم محدن معه همي فرق   \n",
       "4  بندر بن فهد            5     دورت في كل الوجيه حسيت غربه بينهم   \n",
       "\n",
       "  SingerNationality SongDialect  \\\n",
       "0           morocco    meghribi   \n",
       "1           morocco    meghribi   \n",
       "2           morocco    meghribi   \n",
       "3           morocco    meghribi   \n",
       "4           morocco    meghribi   \n",
       "\n",
       "                                        Clean_Lyrics  \\\n",
       "0  ['اروح', 'لاحبابي', 'والاقي', 'الفرح', 'ساكن',...   \n",
       "1     ['ابتسم', 'لافراحهم', 'وانا', 'الهم', 'احترق']   \n",
       "2   ['واسل', 'جروحي', 'ترى', 'حس', 'بعذابي', 'منهم']   \n",
       "3  ['وبالحقيقه', 'انصدم', 'محدن', 'معه', 'همي', '...   \n",
       "4        ['دورت', 'الوجيه', 'حسيت', 'غربه', 'بينهم']   \n",
       "\n",
       "                                Lyrics_lemmatized  \n",
       "0  ['اروح', 'احباب', 'اقي', 'فرح', 'ساكن', 'عين']  \n",
       "1        ['ابتسم', 'افراح', 'وان', 'هم', 'احترق']  \n",
       "2       ['اسل', 'جرح', 'رأى', 'حس', 'عذاب', 'من']  \n",
       "3   ['حقيقه', 'انصدم', 'محدن', 'مع', 'هم', 'فرق']  \n",
       "4           ['دورة', 'وجيه', 'حسي', 'غرب', 'بين']  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ_sy1M0EoLL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2ho1xZqEoLQ"
   },
   "outputs": [],
   "source": [
    "X_feature = pd.DataFrame(Lyrics_df['Lyrics_lemmatized'])\n",
    "y = Lyrics_df['SongDialect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYMrnM96EoLU"
   },
   "outputs": [],
   "source": [
    "# Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6ycITL6EoLX"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyz6TLkPyHFN"
   },
   "outputs": [],
   "source": [
    "X_train= X_train.Lyrics_lemmatized.apply(lambda x:\" \".join(eval(x)))\n",
    "X_test= X_test.Lyrics_lemmatized.apply(lambda x:\" \".join(eval(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "S9BkW15w6u4V",
    "outputId": "65fd9ec9-2438-403f-84e7-610d3c6e576d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23716                           مارح ينحكى ينكتب ينقال كلام\n",
       "504682                        سامحنى لما اقولهالك دى مش سهل\n",
       "503051    ايامي احلامي عم يوعى غرام عم شاف ادامي سهر نام...\n",
       "206440                                 داب حجر رجع قلب رقيق\n",
       "189841                                           حواجب ازاى\n",
       "                                ...                        \n",
       "318389                                      دخل خليك مقابيل\n",
       "107437                         اني هس موت اريد اضل اتعب احب\n",
       "215589                        اه عاللي حب و طال صبر علي هوى\n",
       "128986                                و زعل حارب عيونى منام\n",
       "109969                                             فهم معنى\n",
       "Name: Lyrics_lemmatized, Length: 420228, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WtJ4hz2V7qm1",
    "outputId": "d28c2b2f-1ace-4bb6-a8bc-033025676b67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420228,)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IP7g1IL_7wkR",
    "outputId": "4e0d3d22-c926-4d34-a020-16d1044aaf99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105058,)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRMtAfSwEoLc"
   },
   "source": [
    "Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_SU86UjEoLd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf_fit = tfidf_vect.fit(X_train)\n",
    "\n",
    "tfidf_train = X_tfidf_fit.transform(X_train)\n",
    "tfidf_test = X_tfidf_fit.transform(X_test)\n",
    "\n",
    "X_train_vect = (tfidf_train)\n",
    "X_test_vect = (tfidf_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKZ2JQbWEoLg"
   },
   "source": [
    "Final Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HUlLc0-EoLh"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "L1ZTsfCyEoLk",
    "outputId": "4bebea7d-138e-448b-948f-097bbd6fe7c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marwa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'gulf') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 9299.149 / predict time: 84.597 ---- precision: 0.68 / Recall: 0.667 / Accuracy: 0.667\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall,fscore, support = score(y_test, y_pred, pos_label='gulf', average='weighted')\n",
    "print('Fit time: {} / predict time: {} ---- precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision,3), round(recall,3), round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htCzlJcSEoLo",
    "outputId": "9e20c05c-6ad9-45d5-8ec8-8879755247cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marwa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'gulf') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 4.731 / predict time: 84.597 ---- precision: 0.599 / Recall: 0.498 / Accuracy: 0.498\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "precision, recall,fscore, support = score(y_test, y_pred, pos_label= 'gulf', average='weighted')\n",
    "print('Fit time: {} / predict time: {} ---- precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision,3), round(recall,3), round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NLP_Models_(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
